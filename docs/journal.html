<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_loc24jlw8363-0>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-0,decimal) ". "}ol.lst-kix_loc24jlw8363-7.start{counter-reset:lst-ctn-kix_loc24jlw8363-7 0}.lst-kix_loc24jlw8363-5>li{counter-increment:lst-ctn-kix_loc24jlw8363-5}.lst-kix_loc24jlw8363-5>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-5,lower-roman) ". "}.lst-kix_bkgnpi2go7df-7>li:before{content:"\00274f  "}.lst-kix_loc24jlw8363-6>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-6,decimal) ". "}.lst-kix_bkgnpi2go7df-6>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-6{list-style-type:none}.lst-kix_loc24jlw8363-7>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-7,lower-latin) ". "}.lst-kix_bkgnpi2go7df-5>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-7{list-style-type:none}ol.lst-kix_loc24jlw8363-4{list-style-type:none}ol.lst-kix_loc24jlw8363-5{list-style-type:none}ol.lst-kix_loc24jlw8363-0.start{counter-reset:lst-ctn-kix_loc24jlw8363-0 0}.lst-kix_loc24jlw8363-8>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-8,lower-roman) ". "}ol.lst-kix_loc24jlw8363-8{list-style-type:none}.lst-kix_bkgnpi2go7df-4>li:before{content:"\00274f  "}.lst-kix_bkgnpi2go7df-1>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-2{list-style-type:none}.lst-kix_bkgnpi2go7df-3>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-3{list-style-type:none}ol.lst-kix_loc24jlw8363-0{list-style-type:none}ol.lst-kix_loc24jlw8363-8.start{counter-reset:lst-ctn-kix_loc24jlw8363-8 0}.lst-kix_bkgnpi2go7df-2>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-1{list-style-type:none}ol.lst-kix_loc24jlw8363-3.start{counter-reset:lst-ctn-kix_loc24jlw8363-3 0}.lst-kix_bkgnpi2go7df-0>li:before{content:"\00274f  "}ol.lst-kix_loc24jlw8363-6.start{counter-reset:lst-ctn-kix_loc24jlw8363-6 0}.lst-kix_loc24jlw8363-0>li{counter-increment:lst-ctn-kix_loc24jlw8363-0}.lst-kix_loc24jlw8363-4>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-4,lower-latin) ". "}.lst-kix_loc24jlw8363-3>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-3,decimal) ". "}.lst-kix_loc24jlw8363-1>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-1,lower-latin) ". "}.lst-kix_loc24jlw8363-3>li{counter-increment:lst-ctn-kix_loc24jlw8363-3}.lst-kix_loc24jlw8363-6>li{counter-increment:lst-ctn-kix_loc24jlw8363-6}.lst-kix_loc24jlw8363-2>li:before{content:"" counter(lst-ctn-kix_loc24jlw8363-2,lower-roman) ". "}ol.lst-kix_loc24jlw8363-2.start{counter-reset:lst-ctn-kix_loc24jlw8363-2 0}.lst-kix_loc24jlw8363-2>li{counter-increment:lst-ctn-kix_loc24jlw8363-2}ol.lst-kix_loc24jlw8363-5.start{counter-reset:lst-ctn-kix_loc24jlw8363-5 0}.lst-kix_loc24jlw8363-8>li{counter-increment:lst-ctn-kix_loc24jlw8363-8}.lst-kix_loc24jlw8363-1>li{counter-increment:lst-ctn-kix_loc24jlw8363-1}.lst-kix_loc24jlw8363-4>li{counter-increment:lst-ctn-kix_loc24jlw8363-4}ol.lst-kix_loc24jlw8363-1.start{counter-reset:lst-ctn-kix_loc24jlw8363-1 0}.lst-kix_loc24jlw8363-7>li{counter-increment:lst-ctn-kix_loc24jlw8363-7}ul.lst-kix_bkgnpi2go7df-2{list-style-type:none}ul.lst-kix_bkgnpi2go7df-1{list-style-type:none}ul.lst-kix_bkgnpi2go7df-4{list-style-type:none}ul.lst-kix_bkgnpi2go7df-3{list-style-type:none}ul.lst-kix_bkgnpi2go7df-6{list-style-type:none}ul.lst-kix_bkgnpi2go7df-5{list-style-type:none}.lst-kix_bkgnpi2go7df-8>li:before{content:"\00274f  "}ul.lst-kix_bkgnpi2go7df-8{list-style-type:none}ul.lst-kix_bkgnpi2go7df-7{list-style-type:none}ol.lst-kix_loc24jlw8363-4.start{counter-reset:lst-ctn-kix_loc24jlw8363-4 0}ul.lst-kix_bkgnpi2go7df-0{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c43{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9ead3;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#ffffff;border-bottom-style:solid}.c18{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9d2e9;border-left-style:solid;border-bottom-width:1pt;width:378.8pt;border-top-color:#ffffff;border-bottom-style:solid}.c41{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9ead3;border-left-style:solid;border-bottom-width:1pt;width:408.8pt;border-top-color:#ffffff;border-bottom-style:solid}.c2{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9d2e9;border-left-style:solid;border-bottom-width:1pt;width:244.5pt;border-top-color:#ffffff;border-bottom-style:solid}.c33{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#d0e0e3;border-left-style:solid;border-bottom-width:1pt;width:69pt;border-top-color:#000000;border-bottom-style:solid}.c72{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9d2e9;border-left-style:solid;border-bottom-width:1pt;width:261pt;border-top-color:#ffffff;border-bottom-style:solid}.c22{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#ead1dc;border-left-style:solid;border-bottom-width:1pt;width:99pt;border-top-color:#ffffff;border-bottom-style:solid}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fce5cd;border-left-style:solid;border-bottom-width:1pt;width:80.2pt;border-top-color:#000000;border-bottom-style:solid}.c70{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9ead3;border-left-style:solid;border-bottom-width:1pt;width:433.5pt;border-top-color:#ffffff;border-bottom-style:solid}.c67{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9ead3;border-left-style:solid;border-bottom-width:1pt;width:432pt;border-top-color:#ffffff;border-bottom-style:solid}.c53{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:384pt;border-top-color:#ffffff;border-bottom-style:solid}.c47{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fce5cd;border-left-style:solid;border-bottom-width:1pt;width:68.2pt;border-top-color:#000000;border-bottom-style:solid}.c16{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#ead1dc;border-left-style:solid;border-bottom-width:1pt;width:111pt;border-top-color:#ffffff;border-bottom-style:solid}.c39{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#d0e0e3;border-left-style:solid;border-bottom-width:1pt;width:83.2pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#d9d2e9;border-left-style:solid;border-bottom-width:1pt;width:266.2pt;border-top-color:#ffffff;border-bottom-style:solid}.c42{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#f9cb9c;border-left-style:solid;border-bottom-width:1pt;width:99pt;border-top-color:#ffffff;border-bottom-style:solid}.c48{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#ffffff;border-bottom-style:solid}.c5{margin-left:108pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c1{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c0{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c35{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Courier New";font-style:normal}.c23{color:#d0e0e3;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c26{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c38{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Courier New";font-style:normal}.c24{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c51{color:#000000;font-weight:400;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:700;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c69{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial"}.c28{margin-left:101.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c60{margin-left:95.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c20{margin-left:36pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c54{margin-left:34.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c68{color:#000000;font-weight:400;font-size:10pt;font-family:"Arial"}.c27{margin-left:108pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c11{margin-left:50.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c19{margin-left:72pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c49{font-size:10pt;font-family:"Courier New";color:#434343;font-weight:400}.c52{margin-left:96pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c8{border-spacing:0;border-collapse:collapse;margin-right:auto}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c34{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c12{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c74{margin-left:59.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c57{text-decoration:none;vertical-align:baseline;font-style:normal}.c50{font-family:"Courier New";color:#434343;font-weight:400}.c29{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c64{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c32{margin-left:72pt;padding-left:0pt}.c13{color:inherit;text-decoration:inherit}.c55{orphans:2;widows:2}.c7{padding:0;margin:0}.c6{background-color:#ffffff;color:#76a5af}.c31{font-size:18pt;font-weight:700}.c56{font-family:"Courier New";font-weight:400}.c65{width:33%;height:1px}.c46{padding-left:0pt}.c58{background-color:#ffd966}.c61{vertical-align:sub}.c25{margin-left:36pt}.c14{background-color:#ffffff}.c59{margin-left:72pt}.c71{font-size:9pt}.c66{text-indent:36pt}.c73{background-color:#fce5cd}.c75{font-weight:700}.c37{height:11pt}.c62{height:81pt}.c4{height:0pt}.c44{background-color:#fff2cc}.c40{font-style:italic}.c63{background-color:#ffff00}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c14 c64"><p class="c9"><span class="c3"></span></p><a id="t.9bd05e7bf92fc9f0d39368bd587dfeea98a81888"></a><a id="t.0"></a><table class="c8"><tbody><tr class="c62"><td class="c53" colspan="1" rowspan="1"><p class="c15"><span class="c31">Software Synthesizer Development Journal</span></p><p class="c15"><span class="c17">CSC 461 2019</span></p><p class="c15 c37"><span class="c17"></span></p></td></tr></tbody></table><p class="c9"><span class="c51 c29"></span></p><a id="t.046519048fd158989fcebbe55ca0c2482cfbe791"></a><a id="t.1"></a><table class="c8"><tbody><tr class="c4"><td class="c44 c48" colspan="1" rowspan="1"><p class="c24"><span class="c29">Introduction</span><span>&nbsp;- This is a diary of the development of a software synthesizer</span></p></td></tr></tbody></table><p class="c9"><span class="c3"></span></p><a id="t.aa1da160eba0c7c27ad6f476b4de1f7b01789b0b"></a><a id="t.2"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 10 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0 start"><li class="c1"><span class="c3">Since this project is mostly about learning about digital sound synthesis I decided to begin by looking for examples of what other people have done. One of the resources I discovered was a short series of YouTube videos detailing how to create a simple software synth. Most of the heavy lifting of actually interacting with the sound card is done with a header file called olcNoiseMaker.h and this will be investigated further in the future.</span></li><li class="c1"><span class="c3">At this point I&rsquo;m using other people&rsquo;s examples as a learning tool. This version is just an early rough draft of what the project will eventually become. </span></li><li class="c1"><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/tgamhuQnOkM&amp;sa=D&amp;ust=1574572716192000">https://youtu.be/tgamhuQnOkM</a></span></li><li class="c1"><span class="c3">The basic idea behind the first video is to evaluate a sine wave function based on a count of the time since the program has started. This function is constantly called in order to determine the value of the amplitude at each sample point.</span></li><li class="c1"><span class="c3">This is illustrated in the following formula:</span></li></ul><a id="t.b45e6765d5d86d70924a7729ce93e76a16bb6b7f"></a><a id="t.3"></a><table class="c54"><tbody><tr class="c4"><td class="c70" colspan="1" rowspan="1"><p class="c24"><span class="c49">double dOutput = sin(dFrequencyOutput * 2 * 3.14159 * dTime);</span></p></td></tr></tbody></table><p class="c9"><span class="c49 c57"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-2 start"><li class="c5"><span class="c3">dFrequencyOutput is the value of the note in Hz that we want to be played</span></li><li class="c5"><span class="c3">2 * 3.14159 is used to convert this frequency value to an angular velocity</span></li><li class="c5"><span class="c3">dTime is a timing counter since the beginning of the program</span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>Examples of the code I wrote while following the video can be found here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test1&amp;sa=D&amp;ust=1574572716195000">https://github.com/iainemslie/CSC461Project/tree/master/Test1</a></span></li><li class="c1"><span class="c3">The second video creates a couple of new functions: one that converts frequency to angular velocity, and the other for selecting and evaluating various different waveforms.</span></li><li class="c1"><span class="c3">The Square Wave simply takes a sine wave and outputs a 1 if it is greater than 0 and -1 if it is less than 0. This is shown in the following formula:</span></li></ul><a id="t.3e32a728f490b587c06048966188620520530db6"></a><a id="t.4"></a><table class="c20"><tbody><tr class="c4"><td class="c67" colspan="1" rowspan="1"><p class="c24"><span class="c50">return 0.3 * sin(w(dHertz) * dTime) &gt; 0.0 ? 1.0 : -1.0;</span></p></td></tr></tbody></table><p class="c9"><span class="c35"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">The Triangle Wave smooths out the curve of the sine wave by returning the arcsin of the standard sine wave from the previous example.</span></li></ul><a id="t.3fcc858cb6289ac1dc486939b5c3de845ce84f7b"></a><a id="t.5"></a><table class="c20"><tbody><tr class="c4"><td class="c43" colspan="1" rowspan="1"><p class="c24"><span class="c50">return asin(sin(w(dHertz) * dTime)) * 2.0 / PI;</span></p></td></tr></tbody></table><p class="c9"><span class="c35"></span></p><p class="c9"><span class="c35"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">The Saw Wave is calculated using two different methods. The mathematical way to generate a sawtooth wave is to sum up all of the sine wave multiples of a particular base frequency. However this is computationally expensive. Another way to approximate it is use the mod function to simulate the addition of multiple sine waves. </span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-1 start"><li class="c24 c32"><span>The first method is shown in the following formula:</span></li></ul><a id="t.1ebec299e58b4d114a5a0f49197c59be029d08cc"></a><a id="t.6"></a><table class="c19"><tbody><tr class="c4"><td class="c43" colspan="1" rowspan="1"><p class="c24"><span class="c38">double dOutput = 0.0;</span></p><p class="c24"><span class="c38">for (double n = 1.0; n &lt; 100.0; n++)</span></p><p class="c24"><span class="c38">&nbsp; &nbsp; &nbsp;dOutput += (sin(n * w(dHertz) * dTime)) / n;</span></p><p class="c24"><span class="c38">return dOutput * (2.0 / PI);</span></p></td></tr></tbody></table><p class="c9 c59"><span class="c38"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-1"><li class="c24 c32"><span class="c3">Here is the second method:</span></li></ul><a id="t.390f89aedd40e460783c6b718cdd6fba3ab52394"></a><a id="t.7"></a><table class="c74"><tbody><tr class="c4"><td class="c41" colspan="1" rowspan="1"><p class="c24"><span class="c50 c71">return (2.0 / PI) * (dHertz * PI * fmod(dTime, 1.0 / dHertz) - (PI / 2.0));</span></p></td></tr></tbody></table><p class="c9"><span class="c3"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>The last sound source created is a pseudo random noise generator. This is used to generate whitenoise by generating a number between 1 and -1. These can be used to create wind effects through filtering or as percussion among other uses.</span></li></ul><a id="t.07162b3db14fce200711d9cf1d52306f23270d48"></a><a id="t.8"></a><table class="c19"><tbody><tr class="c4"><td class="c43" colspan="1" rowspan="1"><p class="c15"><span class="c45">return 2.0 * ((double)rand() / (double)RAND_MAX) - 1.0;</span></p></td></tr></tbody></table><p class="c9 c59"><span class="c45"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">After adding these oscillators the video talks about creating ADSR envelopes to create natural and realistic sounds. ADSR stands for attack, decay, sustain and release. </span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-1 start"><li class="c24 c32"><span class="c3">Attack is how long it takes for a sound to reach its maximum volume</span></li><li class="c24 c32"><span class="c3">Decay is how long it takes to transition from the loudest sound to the sustain level</span></li><li class="c24 c32"><span class="c3">Sustain is the volume during the main part of the sound when held</span></li><li class="c24 c32"><span class="c3">Release is the time it takes for a sound to silence after a key is released</span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">The following diagram shows each of these stages:</span></li></ul><p class="c24 c59"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 426.00px; height: 257.00px;"><img alt="" src="images/image19.png" style="width: 426.00px; height: 257.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">After following along with these videos I have some thoughts on more features I&rsquo;d like to implement.</span></li></ul><ol class="c7 lst-kix_loc24jlw8363-0 start" start="1"><li class="c24 c32"><span class="c3">Including a pink noise, brown noise etc generator.</span></li><li class="c24 c32"><span class="c3">Reading and playback of midi files and real time midi from an instrument</span></li><li class="c24 c32"><span class="c3">GUI control of the various oscillators and then envelope and filters based on the layout of old hardware synthesizers</span></li><li class="c24 c32"><span class="c3">Visual representation of the waveform being output. This would just graph the amplitude values along a timeline for each sample. </span></li><li class="c24 c32"><span class="c3">Implement a file like olcNoiseMaker.h but for use in OSX</span></li><li class="c24 c32"><span class="c3">Create some kind of text to speech synthesizer</span></li></ol><p class="c9"><span class="c3"></span></p><p class="c24"><span class="c3">I&rsquo;d like to build a prototype of the GUI right away. I&rsquo;ve been using visual studio so far so here&rsquo;s a couple of tutorials I&rsquo;m going to read through to learn how to do that. </span></p><p class="c24"><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://docs.microsoft.com/en-us/windows/win32/learnwin32/your-first-windows-program&amp;sa=D&amp;ust=1574572716205000">https://docs.microsoft.com/en-us/windows/win32/learnwin32/your-first-windows-program</a></span></p><p class="c24"><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://docs.microsoft.com/en-us/cpp/windows/walkthrough-creating-windows-desktop-applications-cpp?view%3Dvs-2019&amp;sa=D&amp;ust=1574572716206000">https://docs.microsoft.com/en-us/cpp/windows/walkthrough-creating-windows-desktop-applications-cpp?view=vs-2019</a></span></p><p class="c9"><span class="c3"></span></p><a id="t.ea7562a23c18770d2cd56b70dd387fcca83899e7"></a><a id="t.9"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 11 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">I was thinking about how to add midi input for the synthesizer today. There are big differences in the way that Windows and OSX handle audio interaction and APIs. We will have to decide to only develop for one platform or find a way to write it so that the core of the program is the same but it interacts with the OS differently depending on which platform the user is on. It would be nice to create something that is compatible with the AU or VST interfaces. For now I&rsquo;m going to finish the rest of the video tutorials and then maybe try experimenting with getting midi input from a keyboard and then printing the midi messages to the command line.</span></li><li class="c1"><span class="c3">After spending some more time following the videos the synthesizer now has 6 different oscillators which can be added together to create sounds, an ADSR envelope, the ability to frequency modulate the basic oscillators (hence an LFO as well) and the use of structs to make self contained instruments which can be used to save settings.</span></li><li class="c1"><span>This version can be found at the following link: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test3&amp;sa=D&amp;ust=1574572716208000">https://github.com/iainemslie/CSC461Project/tree/master/Test3</a></span></li><li class="c1"><span class="c3">The next steps I would like to learn more about are parsing real time midi input from a keyboard and using an interactive GUI to change the settings of the synth in real time. Up to now I&rsquo;ve been working on Windows but it might be easier to try experimenting with the Apple CoreMidi API. I might just try making a temporary layout of the graphics. </span></li></ul><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><a id="t.17fcb6cb21b43d282660e08f1ad7dddd28ee25d1"></a><a id="t.10"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 12 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">My goal for today is to connect one of my MIDI keyboards and to read input from it and print the results.</span></li><li class="c1"><span>So after spending some time this morning I&rsquo;ve managed to connect my midi keyboard and get some code running which is able to recognize my midi devices and receive input messages while printing them to the console. This version of the code can be found here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test4&amp;sa=D&amp;ust=1574572716210000">https://github.com/iainemslie/CSC461Project/tree/master/Test4</a></span></li><li class="c1"><span class="c3">At first I tried using OSX core midi but immediately ran into problems so switched back to Windows.</span></li><li class="c1"><span>I based this on the Windows MIDI documentation found here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://docs.microsoft.com/en-us/windows/win32/multimedia/midi-functions&amp;sa=D&amp;ust=1574572716211000">https://docs.microsoft.com/en-us/windows/win32/multimedia/midi-functions</a></span><span>&nbsp;and on some code I found at the following link </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://gist.github.com/yoggy/1485181&amp;sa=D&amp;ust=1574572716212000">https://gist.github.com/yoggy/1485181</a></span></li><li class="c1"><span>I was trying to use masking to get the individual bytes and I was able to determine whether a data message was an on or off from this. I realized while I was doing this that </span><span class="c63">MIDI is big-endian while Windows is little-endian</span><span class="c3">. I will have to think of the best way to deal with this. </span></li><li class="c1"><span class="c3">My next goal is to combine the two programs I have written so that I can use MIDI input from an external device to trigger the synthesizer instead of using the computer QWERTY keyboard.</span></li><li class="c1"><span class="c3">My MIDI keyboard has the option of using its own clock or an external clock to synchronize its MIDI output. This means that the midi messages that are sent are synced to this clock rate. Each of these messages is made up of 3 bytes. </span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-1 start"><li class="c24 c32"><span class="c3">1. Status byte - this determines the type of MIDI message</span></li><li class="c24 c32"><span class="c3">2. Data1</span></li><li class="c24 c32"><span class="c3">3. Data2</span></li></ul><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>Here&rsquo;s a good resource on MIDI messages </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://www.nyu.edu/classes/bello/FMT_files/9_MIDI_code.pdf&amp;sa=D&amp;ust=1574572716213000">https://www.nyu.edu/classes/bello/FMT_files/9_MIDI_code.pdf</a></span></li><li class="c1"><span class="c3">For now I&rsquo;m only interested in the NoteOn and NoteOff messages and the note values contained in the message. I simply want to come up with a way to map these midi note values to the correct frequencies to be output by the synthesizer. I could possibly create an array from 0-127 with the frequency of each note at the associated value.</span></li><li class="c1"><span class="c3">I&rsquo;ve successfully managed to get the correct 0-127 digit number for the midi keys to be printed. I did this through some sneaky bit shifting but there&rsquo;s probably a better way to do it... </span></li><li class="c1"><span class="c3">Now I want to combine what I&rsquo;ve done already in separate programs. I think I&rsquo;ll maybe have to clean up the code and create some header files for each different module. I&rsquo;m not really sure what I&rsquo;m going to do about threading or classes since I&rsquo;m learning C++ as I go and treating it as standard C at the moment. </span></li><li class="c1"><span>I found a nice little formula on wikipedia to convert a MIDI note number to its frequency:</span></li></ul><a id="t.184e5e88015f72c0021c7e2aedb285720cb6bb9a"></a><a id="t.11"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image1.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><p class="c24"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/MIDI_tuning_standard&amp;sa=D&amp;ust=1574572716216000">https://en.wikipedia.org/wiki/MIDI_tuning_standard</a></span></p><p class="c9 c66"><span class="c3"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>This should allow me to simply plug this value into the existing code I have in the synthesizer. Here is the code that I have up until now: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test5&amp;sa=D&amp;ust=1574572716217000">https://github.com/iainemslie/CSC461Project/tree/master/Test5</a></span></li><li class="c1"><span class="c3">I now have to decide what&rsquo;s the best way to combine my midi input program with the synth program. </span></li><li class="c1"><span class="c3">I was having trouble trying to figure out how to integrate all the code. I&rsquo;ve been thinking about how things should be organized so that most of the elements of the synth become classes and objects. For example a preset sound is a class that contains settings for various instrument parameters. Then these can be broken down into every subcomponent like individual oscillators, envelopes, filters etc.</span></li><li class="c1"><span>I wanted to just have the satisfaction of getting the MIDI to play some sounds so I went back to the very beginning and just added it to the MIDI.cpp file. I saved it here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test6&amp;sa=D&amp;ust=1574572716219000">https://github.com/iainemslie/CSC461Project/tree/master/Test6</a></span></li><li class="c1"><span>I made a little recording by playing a midi track in Musescore and sending out the midi info which was captured by the synth program and then recorded by Audacity. This can be found here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://iainemslie.github.io/audio/BWV1013AllemandeFirstSynthRecording.mp3&amp;sa=D&amp;ust=1574572716220000">https://iainemslie.github.io/audio/BWV1013AllemandeFirstSynthRecording.mp3</a></span></li></ul><p class="c9"><span class="c3"></span></p><a id="t.ebda5eae489cdf3b953202c57ac2270ccc5df3bb"></a><a id="t.12"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 13 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>This morning I began by creating a class file which models the interface of the Korg MS20 synthesizer. It&rsquo;s basically just a bunch of private variables for controlling the synthesizer and setters to change them. I wanted to do this to start thinking about how I&rsquo;m going to organize everything and how the GUI will work. This can be found here: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test7&amp;sa=D&amp;ust=1574572716221000">https://github.com/iainemslie/CSC461Project/tree/master/Test7</a></span></li><li class="c1"><span class="c3">If I were to model the MS20 then there would be two oscillators which different waveform options then various modulation options and filters etc. The way I&rsquo;m envisioning things is that I can create class files for each subcomponent i.e. each section of the signal flow (VCO, filters, envelopes etc.) then these can be combined to model existing synthesizers or to create really unusual things like having 50 oscillators combined together doing additive synthesis. I think the best way to do things is to make everything as modular as possible. I&rsquo;d have base classes that are then overridden if necessary. </span></li><li class="c1"><span class="c29">Thinking about additive synthesis:</span><span class="c3">&nbsp;It would be cool to do frequency domain spectrum analysis of different instruments in order to emulate them by mixing together oscillators to mimic the overtone partials above some fundamental. A way of doing this is to have a bunch of oscillator objects which feed into some mixer object through which their relative volumes can be adjusted. </span></li></ul><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>I&rsquo;m going to pause for a little bit on writing code and take some notes from the book BasicSynth: </span><span class="c12"><a class="c13" href="https://www.google.com/url?q=http://basicsynth.com/&amp;sa=D&amp;ust=1574572716223000">http://basicsynth.com/</a></span></li><li class="c1"><span class="c29 c75">Chapter 1 Notes:</span></li><li class="c1"><span>If we imagine a point moving around the unit circle anti-clockwise starting at point (1,0). Then the line formed by this point and the origin forms an angle </span><img src="images/image2.png"><span class="c3">&nbsp;with the x-axis.</span></li></ul><p class="c21 c25"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 447.50px; height: 338.49px;"><img alt="" src="images/image18.png" style="width: 447.50px; height: 338.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">We can see that the sin function gives us the y-coordinate of the point on the unit circle and the cos function gives us the x-coordinate of the point on the unit circle.</span></li></ul><a id="t.bb1e18160a4669386bf4b168f937eabd2aaa8823"></a><a id="t.13"></a><table class="c28"><tbody><tr class="c4"><td class="c10" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = sin(0)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 0</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = cos(0)</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 1</span></p></td></tr><tr class="c4"><td class="c10" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = sin(&pi;/2)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 1</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = cos(&pi;/2)</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 0</span></p></td></tr><tr class="c4"><td class="c10" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = sin(&pi;)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 0</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = cos(&pi;)</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = -1</span></p></td></tr><tr class="c4"><td class="c10" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = sin(3&pi;/2)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = -1</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = cos(3&pi;/2)</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c34"><span class="c3">y = 0</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>Here is a graph of the function f(x) = sin(x). As we can see from the picture it is a repeating wave with a period of 2</span><img src="images/image3.png"><span>~ 2(3.14159) and an amplitude of 1. This means that the curve moves from 0 up to 1 and back to zero in the time of </span><img src="images/image3.png"><span>. Then from 0 down to -1 and back up in the time of </span><img src="images/image3.png"><span class="c3">. cos can be thought of as a phase shifted sine wave.</span></li></ul><p class="c21 c25"><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 415.00px; height: 148.01px;"><img alt="" src="images/image16.png" style="width: 415.00px; height: 148.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">We can write the sine function as follows.</span></li></ul><a id="t.dd286f1729a19ba11867bd6f21a8a5cacb2efbd3"></a><a id="t.14"></a><table class="c11"><tbody><tr class="c4"><td class="c18" colspan="1" rowspan="1"><p class="c21"><img src="images/image4.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">Changing the amplitude will scale the maximum and minimum y values. Changing the period will change the frequency of the waveform. Phase shift moves the function along the x-axis. Vertical shift moves the function up or down the y-axis.</span></li><li class="c1"><span class="c3">This is useful because we can use the amplitude in audio to control volume. Phase shifting is used in many effects and in filtering. We can phase invert a signal x by taking sin(-x). Taking sin(x) + sin(-x) will cancel the signal. (it sums to zero)</span></li><li class="c1"><span class="c3">Fourier proved mathematically that any period waveform can be created by summing together infinitely many sine waves. Since pitched sound is a periodic waveform we can represent any pitched sound as summing of sine waves.</span></li><li class="c1"><span class="c3">As an example; take the equation:</span></li></ul><a id="t.d55290ce4da6e3ee39fd1ec5d8bee3cb7f0cbf0f"></a><a id="t.15"></a><table class="c11"><tbody><tr class="c4"><td class="c18" colspan="1" rowspan="1"><p class="c21"><img src="images/image5.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">This gives us the interesting waveform:</span></li></ul><p class="c21 c25"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.50px; height: 210.58px;"><img alt="" src="images/image20.png" style="width: 547.50px; height: 210.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">If we were to measure the amplitude (the value of the function on the y-axis) at some regularly spaced time (intervals on the x-axis) then we can get a digital representation of the waveform. According to the Shannon-Nyquist Theorem we need this sampling rate to be at least twice the frequency of the highest frequency of some band limited audio source. Since human hearing is around 20Hz to 20,000Khz we can sample at twice this to fully capture the sound for our perceptions. The standard CD sample rate is 44,100 Hz so this is a good choice to start with.</span></li><li class="c1"><span class="c3">Frequency is measured in cycles per second. So if we have a sound at 440Hz then the waveform repeats 440 times a second. So the time of one period of the waveform is 1/440th of a second. We can write this as follows:</span></li></ul><p class="c24"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><a id="t.0788fb64e843ea35d5604f3cb95a52eb4c404846"></a><a id="t.16"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image6.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><p class="c9"><span class="c17"></span></p><a id="t.d87b04c2ebfd575216962352558b5a0a34076a71"></a><a id="t.17"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image7.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>The number of samples generated for a given time period is as follows:</span></li></ul><a id="t.066d9d7ac3e4702276fdb58b364e041d695d4460"></a><a id="t.18"></a><table class="c60"><tbody><tr class="c4"><td class="c36" colspan="1" rowspan="1"><p class="c21"><img src="images/image8.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">We need to represent the time values as doubles but can use integers to represent the sample numbers.</span></li><li class="c1"><span>For quantizing the amplitude we can use a 16 bit value since this is the typical standard used. This is because it gives us around 96dB of dynamic range which closely matches that produced by music. Human hearing doesn&rsquo;t perceive small changes in amplitude because of this it is represented using a logarithmic scale. The decibel scale represents the smallest change in amplitude that humans can perceive as 1dB. This can be defined as:</span></li></ul><a id="t.9d7c3210b7aba4921a4e8b104ad18572ecdad1ec"></a><a id="t.19"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image9.png"><span class="c17">&nbsp;</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">Since each bit represents a power of two increase in the range one bit can represent ~ 6dB thus 16 bits results in 96dB.</span></li><li class="c1"><span class="c58">Internally within the program we should represent the sample amplitude as floats.</span></li><li class="c1"><span class="c29 c30">Chapter 5 Notes:</span></li><li class="c1"><span>To mimic the function of analog oscillators with the computer we want to evaluate a period function for each sample time. We want to determine the phase increment. This is the amount that we move around the unit circle for each sample (the distance between samples on the x-axis in the graph of the sin function). We can find the phase increment for one sample using the following:</span></li></ul><a id="t.5cb6790f50c93545aacbe0a603bc7499cb4a3487"></a><a id="t.20"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image10.png"></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span>Where f</span><span class="c61">s</span><span>&nbsp;is the sample rate and 1/f is the time of one period. 2</span><img src="images/image3.png"><span class="c3">radians is the period so we&rsquo;re diving this by the number of samples in one period.</span></li></ul><p class="c9"><span class="c3"></span></p><p class="c24"><span class="c3">Taking a break from the notes; I want to try and rewrite the earliest version of the synth but do it so that individual oscillators can be instantiated as objects from a class.</span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c3">I have implemented the oscillator as a class with its own set of variables which can be changed using getter and setter methods. This should make it easier to create a modular object oriented style for the program.</span></li><li class="c1"><span class="c12"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test8&amp;sa=D&amp;ust=1574572716247000">https://github.com/iainemslie/CSC461Project/tree/master/Test8</a></span></li><li class="c1"><span>I have added a mixer class which takes input signals from two different oscillator sources and adds them together while adjusting their volume. This is mimicking the VCOmixer found on the Korg MS20.</span><span class="c3 c44">&nbsp;If I dynamically allow at runtime the addition of more oscillators to the mixer then this will provide more flexibility later on when adding many number of oscillator to a project. I will have to think about c++ memory management if I do this.</span></li><li class="c1"><span class="c14">I have added MIDI control back into the version I have created with classes. This version can be found here: </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test9&amp;sa=D&amp;ust=1574572716248000">https://github.com/iainemslie/CSC461Project/tree/master/Test9</a></span></li><li class="c1"><span class="c14">The next thing I want to do is to redo the ADSR envelope generator so that it is in its own class. I reused an old version of envelope class I had made earlier. It works but the note off isn&rsquo;t working properly. The note just cuts off immediately when a MIDI key is unpressed instead of fading out. It also doesn&rsquo;t have the proper methods so I should redo this. </span><span class="c6">-&gt;( </span><span class="c6 c40 c69">I later fixed this by removing old lines setting the frequency to be zero from before there was an envelope.)</span></li><li class="c1"><span class="c0">Another thing I need to do is create instrument classes that contain within them the oscillators, envelopes etc. Then there can be a global pitch value for midi sent to this which then sends this to each oscillator of the instrument. I need to figure out how to do this with polyphony as well.</span></li></ul><p class="c9"><span class="c3"></span></p><a id="t.6208eea1fcc83eaf20622cd8345ec95b9fc0d3e9"></a><a id="t.21"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 14 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">Today I&rsquo;m going to start by modifying the ADSR class and header file so that it is set up properly. Then I&rsquo;m going to create an instrument class to contain the various sound modules. Here is what I have before I do this: </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test10&amp;sa=D&amp;ust=1574572716250000">https://github.com/iainemslie/CSC461Project/tree/master/Test10</a></span></li><li class="c1"><span class="c0">I spent some time redoing the envelope class. While doing this I realized I don&rsquo;t have a consistent scheme for naming variables, classes etc across the whole program. I need to think about what system I want to use. </span></li><li class="c1"><span class="c14">I got the program to properly print out the MIDI input devices by using</span><span class="c3 c73">&nbsp;wcout instead of fprintf or cout.</span></li><li class="c1"><span class="c14">To deal with polyphony a note structure is created in the video series </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DroRH3PdTajs&amp;sa=D&amp;ust=1574572716251000">https://www.youtube.com/watch?v=roRH3PdTajs</a></span></li><li class="c1"><span class="c14">I was running into a problem with multiple class definitions but solved using &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c14 c56">#pragma once </span><span class="c14">at the top of the header file</span></li><li class="c1"><span class="c14">I need to fix the envelope with my own formulas or update them from the later video version. </span><span class="c6">-&gt; I did this later but there are still pops when retriggering notes or when playing one note while another is held. I will have to investigate the best way to do polyphony</span><span class="c6 c40">.) I&rsquo;m trying to build up the overall structure of the program at the moment so I&rsquo;m basing code off of the videos but I will get more in depth with each module later on.</span><span class="c14 c23">.</span></li><li class="c1"><span class="c0">I think I&rsquo;ve reached a good level of modularity for now. The next things I should investigate are polyphony, frequency modulation, refining the existing equations I have for oscillators and envelopes. After this I can begin looking at adding more signal processing modules like filters and audio effects. The implementation of the GUI looms as well.</span></li><li class="c1"><span class="c14">Here is the code up to this point: </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/iainemslie/CSC461Project/tree/master/Test11&amp;sa=D&amp;ust=1574572716252000">https://github.com/iainemslie/CSC461Project/tree/master/Test11</a></span></li></ul><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><a id="t.6208eea1fcc83eaf20622cd8345ec95b9fc0d3e9"></a><a id="t.22"></a><table class="c8"><tbody><tr class="c4"><td class="c22" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 14 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">I&rsquo;m going to take some more notes from the BasicSynth book resuming from page 38. </span></li><li class="c1 c37"><span class="c0"></span></li><li class="c1"><span class="c14">The phase increment can be written:</span></li></ul><a id="t.27db90df2fe6b691ca037dc5b47e77a5e42851ae"></a><a id="t.23"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image11.png"></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">Where</span><img src="images/image12.png"><span class="c14">&nbsp;(the angular velocity) represents the signal as radians/second and can be written:</span></li></ul><a id="t.8dd54895aaa2cc72a69825008d66b9323ecca4d5"></a><a id="t.24"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image13.png"></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">To get the value for each sample point of our sine wave function we can use the following formula.</span></li></ul><a id="t.2168e70cf6f38bc1d7c14030d8a6bc919de39392"></a><a id="t.25"></a><table class="c52"><tbody><tr class="c4"><td class="c72" colspan="1" rowspan="1"><p class="c21"><img src="images/image14.png"></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">This is the same method from the videos and implemented in our code. The book is taking the approach of writing the output to a file directly instead of sending samples to the sound card. Since it is taking this approach it illustrates a way of using a for loop to iterate through the sample count for a certain duration of time and evaluating the function at that sample. We are essentially doing the same thing except that our for loop never ends and the oscillator is only outputting sound when keys are pressed.</span></li><li class="c1"><span class="c14">&ldquo;To save processing time, the frequency values for the standard musical </span><span class="c14">scale</span><span class="c14">&nbsp;are usually calculated during program initialization and stored in a table. The pitch can then be quickly converted into frequency by using the pitch value as an index into the frequency table.&rdquo;</span><sup class="c14"><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span class="c14">&nbsp;- </span><span class="c3 c44">Currently I&rsquo;m doing this every time I get a midi note. I should create a lookup table instead.</span></li><li class="c1"><span class="c30 c29 c14">Chapter 6 Envelope Generators</span></li><li class="c1"><span class="c14">We can represent an ADSR envelope attack or decay with the equation for a line</span></li></ul><a id="t.82757c2ddd0d89afac0d6eea3dbf52a44a82cc0c"></a><a id="t.26"></a><table class="c27"><tbody><tr class="c4"><td class="c2" colspan="1" rowspan="1"><p class="c21"><img src="images/image15.png"></p></td></tr></tbody></table><p class="c24 c25"><span class="c0">Where y represents amplitude and x represents time. </span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">We can represent an ADSR envelope attack or decay with the equation for a line</span></li></ul><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c0"></span></p><a id="t.4d47fc2d17cccfed7581ffcdb5dc56d15fbed591"></a><a id="t.27"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">Oct 17 - 22 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">Significant wrangling of getting CMake to work inside Visual Studio to build the project. This took much more work than initially thought.</span></li><li class="c1"><span class="c0">The CMake addon needs to be installed in Visual Studio.</span></li><li class="c1"><span class="c0">CMake will generate the Visual Studio solution project files needed to build the project. On Linux CMake will create a Makefile that is run to build the project.</span></li><li class="c1"><span class="c0">Building on Linux is possible from the command line.</span></li></ul><p class="c24 c25"><span class="c0">For example:</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; &nbsp; $ cd .../CSC461Project/MKUltra/MKUltra</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; &nbsp; $ cmake -H. -Bbin &amp;&amp; cmake --build bin</span></p><p class="c24 c25"><span class="c0">The executable is at:</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; &nbsp; $ ./bin/MKUltra</span></p><p class="c24 c25"><span class="c0">To clean up all the CMake files and start fresh:</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; &nbsp; $ rm -R bin</span></p><p class="c24 c25"><span class="c0">CMake creates the &ldquo;bin&rdquo; directory in which to build the software. This keeps the object code away from the source code.</span></p><p class="c9"><span class="c0"></span></p><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">To run with Visual Studio, select Open Project Folder. Find the project&rsquo;s root directory. It should be &hellip;\CSC461Project\MKUltra with a top-level CMakeLists.txt file.</span></li><li class="c1"><span class="c0">The file that has main() in it needs to be selected to be the entry-point of the project. This can be done by right-clicking on synth.cpp and selecting from the drop-down menu.</span></li><li class="c1"><span class="c0">Building on Linux</span></li></ul><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><a id="t.a8aaea945a772976b34b62da9e867ef6b111a933"></a><a id="t.28"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 22 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">Note: Running with the olcNoiseMaker.h library requires that a 32-bit (x86) executable be made. An exception somewhere in the threading library is thrown if ran in 64-bit (x64). Also, I read that the difference between </span><span class="c14">Debug mode and</span><span class="c0">&nbsp;Release mode can have an effect on the context of threads, and may be a source of mysterious errors on Windows.</span></li><li class="c1"><span class="c0">Import Test 11 code into the CMake build framework to build on Windows.</span></li><li class="c1"><span class="c0">Small hack needed to get woc.szPname and pmic.szPname to be pushed back into the vector of wstrings. Just a conversion between strings and wstrings.</span></li><li class="c1"><span class="c0">Some build warnings for signed/unsigned mismatch and left shifts could potentially be undefined behaviour. These will be fixed in future commits.</span></li><li class="c1"><span class="c0">Building in Visual Studio requires that the winmm.lib library be added to the list of libraries in the Configuration Settings.</span></li></ul><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><a id="t.38b2f6ee88d2b99a6d42785ac95d7db2c92f1183"></a><a id="t.29"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">Oct 23 - 25 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">No commits happened in this time, but significant effort was made to compile the PortAudio portable audio library on Visual Studio via CMake. So far, this effort has been in vain.</span></li><li class="c1"><span class="c0">The last stable release of PortAudio is from 2016 and is Version 19.6.0.</span></li></ul><p class="c24 c25"><span class="c0">In Linux PortAudio is a package and can be installed via a command such as:</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; $ sudo apt-get install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0</span></p><p class="c24 c25"><span class="c0">This command hasn&rsquo;t been tested for Ubuntu, as I am developing on OpenBSD, which uses a command such as:</span></p><p class="c24 c25"><span class="c0">&nbsp; &nbsp; $ sudo pkg_add portaudio-svn</span></p><p class="c24"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On OSX, using Homebrew:</span></p><p class="c24"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; $ sudo brew install portaudio</span></p><p class="c24"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On OSX, using MacPorts:</span></p><p class="c24"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; $ sudo port install portaudio</span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><a id="t.4a62abddc2b578f673ec757e312bd755f2a990a8"></a><a id="t.30"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 26 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">Building synthesizer with PortAudio library. It currently only outputs a sine wave.</span></li><li class="c1"><span class="c0">CMakeLists.txt file now looks for the portaudio library under /usr/local. This should make it able to be found on OSX with Homebrew or MacPorts.</span></li><li class="c1"><span class="c0">PI constant changed to M_PI, which is found in &lt;cmath&gt;. An #ifndef defined in sound.h is if it isn&#39;t found in &lt;cmath&gt;.</span></li><li class="c1"><span class="c0">A new Sound class is developed that currently only outputs a Sine wave in mono. Also, a ScopedPaHandler class is used to terminate PortAudio when out of scope.</span></li><li class="c1"><span class="c0">olcNoiseMaker.h is no longer used. Code that used it is temporarily commented out via #if 0 / #endif. The synth code is not currently hooked up to PortAudio. The MIDI code is also temporarily commented out.</span></li><li class="c1"><span class="c0">May possibly build on Windows, but only Unix has been tested so far. </span></li></ul><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><a id="t.16d7c37339f5eeb614eece2068dd96d4d30969fa"></a><a id="t.31"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 27 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c14">Not yet committed, but work on hooking up PortAudio into the current synthesizer framework is in progress. PortAudio has been integrated, but the sound quality is not yet of a high standard. There is too much jitter, as doing large computations in the audio callback with functions such as sin() for each sample is too resource intensive to get real time response. A sample of the jitter is available at </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://iainemslie.github.io/audio/2019-10-27_Jitter.mp3&amp;sa=D&amp;ust=1574572716272000">https://iainemslie.github.io/audio/2019-10-27_Jitter.mp3</a></span><span class="c0">&nbsp;</span></li><li class="c1"><span class="c0">The olcNoiseMaker.h library uses a double dTime for synchronization between all functions. This approach doesn&rsquo;t scale well. A better approach, as shown starting on page 80 of the BasicSynth book, is to use a wavetable of pre-computed values for one period of a particular waveform. This type of setup is in line with the expected behaviour of the PortAudio library. More work and research into this type of setup is needed to understand the impact upon the architecture of the entire project.</span></li></ul><p class="c9"><span class="c0"></span></p><a id="t.29e2db600f5d0a407495ab937d74fb5f1eef9ce4"></a><a id="t.32"></a><table class="c8"><tbody><tr class="c4"><td class="c42" colspan="1" rowspan="1"><p class="c15"><span class="c26">October 28 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">PortAudio on OpenBSD seems to not have timing implemented, as through the library function Pa_GetStreamTime(). The currentTime structure member from the TimeInfo struct is always zero, which means that an error has occurred. I can not determine what the error is, though. Perhaps there is a misconfiguration of the library on my part.</span></li><li class="c1"><span class="c0">I have used the function clock_gettime(CLOCK_MONOTONIC, &amp;nowTime) to get the current time, and the macro timespecsub(&amp;nowTime, &amp;startTime, &amp;delta) to find the length of the passage of time. This is my own implementation, instead of using what is offered by PortAudio. Hopefully this is a temporary solution and either PortAudio is made to work properly, and/or this type of timing is not needed (unlikely, as I am sure synchronizing with MIDI would need some sort of timing with the audio).</span></li></ul><p class="c9"><span class="c0"></span></p><a id="t.80c2f56d766e0fbf1f87598d63f2d47ad9a6a8f5"></a><a id="t.33"></a><table class="c8"><tbody><tr class="c4"><td class="c16" colspan="1" rowspan="1"><p class="c15"><span class="c26">November 21 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">We looked at a variety of ways to implement the GUI. Some time was spent trying to create application windows using graphics libraries such as wxWidgets and the Win32 API. While these may be useful in a lot of cases they were too much work to learn and beyond the scope of this particular project. Instead, we decided to use the Juce application framework. Juce offers a large library of GUI and plug-in features for use in mobile and desktop applications. We had decided early on that cross-platform support would be ideal. Juce gave us the option of writing C++ code that could be built on a variety of operating systems including; Linux, Windows, OSX, iOS and Android. In addition, it provided us with a much easier way to implement an appealing and interactive graphical user interface. Chris was able to create a mockup of the basic layout idea we had using Juce. This version is pictured below.</span></li><li class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image23.png" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c1"><span class="c0">This particular layout is mimicking the layout of traditional hardware performance synthesizers which prioritize ease of use for musicians rather than trying to allow for every possible method of creating sounds. </span></li><li class="c1"><span class="c0">Each of the individual panels will be filled in with knobs, sliders and buttons which will allow the user to interact with the synthesizer. For example, the oscillator components will include a type (sine, square, sawtooth etc.), an octave range (8&rsquo;, 16&rsquo;, 32&rsquo; - like organ stops), pulse width etc. These panels will be implemented as a panel class which will be inherited by individual panel types such as oscillator, mixer, HPF etc.</span></li><li class="c1"><span class="c0">We&rsquo;re going to complete the panel layout as well as combining the work we did earlier to create the oscillators and envelope classes. Then we&rsquo;re going to try implementing more features such as reverb, delay, LFO etc. Ideally it will be possible to swap panels in and out or have, for example, an individual effects panel which can be swapped out with different effects.</span></li><li class="c1"><span class="c0">As of right now we are able to use the computer&rsquo;s built in midi interface to control the synth, as well as the onboard keyboard. The first oscillator we have is a simple sine wave. We will have to build individual classes for each type of oscillator which will then be selected by the user through the GUI. </span></li><li class="c1"><span class="c0">This afternoon I was able to properly implement the use of the square wave which can now be selected alongside the sine wave. I created a setOscillatorType method which is part of the Synth.h file. When called, this method clears the existing voices and sounds and adds in new voices. I was having problems before because I didn&rsquo;t really understand what was happening. This allows synthAudioSource.setOscillatorType(OSC_TYPE) to be called in the main component as the result of a GUI setting change. </span></li><li class="c1"><span class="c0">There are problems using the existing method of the square wave however. It sounds like it&rsquo;s out-of-tune the further from A440 you get. Also the square wave is perceptually much louder than the sine but this is to be expected.</span></li><li class="c1"><span class="c14">Here&rsquo;s a demo of the new sine wave using the Juce framework. Unfortunately there are lots of clicks since the envelope hasn&rsquo;t been implemented yet. </span><span class="c12 c14"><a class="c13" href="https://www.google.com/url?q=https://iainemslie.github.io/audio/Brittania.mp3&amp;sa=D&amp;ust=1574572716275000">https://iainemslie.github.io/audio/Brittania.mp3</a></span></li><li class="c1"><span class="c63">The following will be some notes on digital filters from BasicSynth</span></li><li class="c1"><span class="c0">Filters alter the spectrum of a sound by amplifying or attenuating selected frequencies. BasicSynth lays out an intuitive understanding of filters as resulting from the addition of waveforms that are out of phase from one another, resulting in cancellation or addition of waveforms. This leads to the important audio phenomenon of phase cancellation. Audio effects such as filters, chorus, flangers and phasers make use of this idea.</span></li><li class="c21 c46 c25"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 347.50px; height: 210.42px;"><img alt="" src="images/image17.png" style="width: 347.50px; height: 210.42px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c1"><span class="c0">In the image above. We have the graph of two functions a=sin(x) and b=sin(x+&pi;). Since the period of both functions is 2&pi; and they are phase offset by &pi; then the peaks of &ldquo;a&rdquo; occur exactly where the valleys of &ldquo;b&rdquo; are. This means that when they are summed together the result will be equal to y=0. </span></li><li class="c21 c25 c46"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 352.00px; height: 214.54px;"><img alt="" src="images/image21.png" style="width: 352.00px; height: 214.54px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c1"><span class="c0">In the image above we have two functions a(x) and b(x) which are both equal to the same function sin(x). When these two functions are added together c(x) = a(x) + b(x), the result is a waveform with twice the amplitude of the component waveforms.</span></li><li class="c1"><span class="c0">In digital signals we can sum samples by adding them together and a phase shift can be created by delaying the samples by some amount of sample times. These samples can be stored in a buffer and then later added back to the signal creating a sum of the original waveform with a phase shifted version of itself.</span></li><li class="c1"><span class="c0">The different types of filters can be created by combining the delayed sample with the current sample in different ways. A low-pass filter is created by adding a delayed sample to the current one - attenuating lower frequencies. A high-pass filter can be created by subtracting a delayed sample - attenuating higher frequencies. </span></li><li class="c1"><span class="c0">If we add two delayed samples to the current one this creates a notch filter. If we subtract two delayed samples from the current one this creates a band-pass filter. A comb filter uses multiple delayed samples.</span></li><li class="c1"><span class="c0">The delayed sample can be multiplied by a value between 0 and 1 to reduce the amplitude. This reduces the filtering effect and flattens out the curve.</span></li></ul><p class="c9"><span class="c0"></span></p><a id="t.ec52c45b8a7bb94ac7963fdd95bae10a6c56443a"></a><a id="t.34"></a><table class="c8"><tbody><tr class="c4"><td class="c16" colspan="1" rowspan="1"><p class="c15"><span class="c26">November 22 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">Last night I made another demo of the synth but noticed that we were getting clicking sounds when lots of notes are played. This is due to the envelope features not being implemented yet.</span></li><li class="c1"><span class="c0">The original version of the synth used the envelope to attenuate the level of the sound by calculating the time since the last key was pressed or released. In the Juce version we are outputting sound directly from each waveform class. It would be better to think about the &ldquo;signal path&rdquo; through the synth. So that we output the results of each module to some common mixer or function which then sounds the results out to the soundcard. I will look into doing this in the afternoon. After the envelope I&rsquo;m going to implement LFO and resume the work on filters.</span></li><li class="c1"><span class="c0">I should create a base oscillator class then individual types sine, square etc which inherit from it but differ only in their method of generating samples</span></li><li class="c1"><span class="c0">Juce contains and ADSR class which I will use to implement the envelope.</span></li></ul><a id="t.be7165b7776d3e3d6f2d466d0bafe47de823fac2"></a><a id="t.35"></a><table class="c8"><tbody><tr class="c4"><td class="c16" colspan="1" rowspan="1"><p class="c15"><span class="c26">November 23 2019</span></p></td></tr></tbody></table><ul class="c7 lst-kix_bkgnpi2go7df-0"><li class="c1"><span class="c0">I spent the afternoon messing around with getting the GUI interface set up and getting it to change settings within the synth. I was having trouble figuring out how to do this but ended up passing a reference to the synthAudioSource object into the OscillatorComponent through the constructor. This allows the buttonPressed() callback function inside the OscillatorComponent to call synthAudioSource.setOscillator() and now it is possible to change the waveform of the oscillator while the synth is in use. Here&rsquo;s a picture of the current GUI configuration:</span></li><li class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 568.50px; height: 358.05px;"><img alt="" src="images/image22.png" style="width: 568.50px; height: 358.05px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c0"></span></p><p class="c9"><span class="c0"></span></p><hr class="c65"><div><p class="c15 c55"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c57 c68">&nbsp;BasicSynthPg41</span></p></div></body></html>